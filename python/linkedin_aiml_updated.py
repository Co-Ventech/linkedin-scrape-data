# -*- coding: utf-8 -*-
"""LinkedIn_AIML (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SvvCZm_1x4vt4jNtxWZ3bq6Sh6H2TuAy

## Importing Required Libraries and Loading the Data
"""


import json
import pandas as pd
import re
import string
from datetime import datetime, timezone
# from IPython.print import print

file_path = r'C:\Users\Dell\Downloads\apify_jobs_raw.json'  # <-- "r" handles backslashes'  # Use relative path for Node.js compatibility

#Load JSON data
with open(file_path, 'r', encoding='utf-8') as f:
    data = json.load(f)

# Normalize JSON depending on structure
if isinstance(data, dict) and 'data' in data:
    jobs = data['data']
elif isinstance(data, list):
    jobs = data
else:
    raise ValueError("Unrecognized JSON structure.")

# Convert to DataFrame
df = pd.json_normalize(jobs)

# Filter only remote jobs
df = df[df['workRemoteAllowed'] == True].reset_index(drop=True)

# Preview
print(f" Remote jobs found: {df.shape[0]}")
# print(df[['id', 'title', 'company.name', 'location.linkedinText', 'workRemoteAllowed']].head())

"""## KPI 1: Job Description Quality KPI"""

def jd_quality_score(text):
    text = str(text)
    score = 0.0
    length = len(text)

    # Length check
    if length > 300:
        score += 0.4

    # Bullet point or list style formatting
    if '-' in text or 'â€¢' in text:
        score += 0.2

    # Structure keywords
    if any(kw in text.lower() for kw in ['responsibilities', 'requirements', 'qualifications', 'skills']):
        score += 0.2

    # Minimal punctuation noise
    symbol_count = sum(1 for char in text if char in string.punctuation)
    symbol_ratio = symbol_count / max(length, 1)
    if symbol_ratio < 0.05:
        score += 0.2

    return round(min(score, 1.0), 2)

df['kpi_jd_quality'] = df['descriptionText'].apply(jd_quality_score)
# print(df[['title', 'kpi_jd_quality']].head())

"""## KPI 2: Domain Fit KPI (QA, Test Automation, Web Dev, AI, ML, UI/UX)

"""

target_domains = {
    "qa": [
        "qa", "quality assurance", "test automation", "testing", "manual testing",
        "test case", "test plan", "selenium", "cypress", "jmeter", "test rail",
        "jira", "bug report", "defect tracking", "regression testing", "functional testing",
        "performance testing", "security testing", "api testing", "ui testing",
        "user acceptance testing", "uat", "agile testing", "scrum", "ci/cd testing"
    ],
    "web": [
        "frontend", "backend", "web developer", "javascript", "react", "vue",
        "angular", "html", "css", "node", "python", "django", "flask", "java",
        "spring boot", "c#", ".net", "php", "laravel", "ruby on rails", "go",
        "golang", "express.js", "typescript", "rest api", "graphql", "docker",
        "kubernetes", "aws", "azure", "gcp", "sql", "mongodb", "postgresql",
        "microservices", "redux", "webpack", "babel", "next.js", "nuxt.js"
    ],
    "ai": [
        "ai", "ml", "machine learning", "deep learning", "data scientist", "pytorch",
        "tensorflow", "keras", "scikit-learn", "nlp", "natural language processing",
        "computer vision", "reinforcement learning", "data analysis", "r", "julia",
        "spark", "hadoop", "neural networks", "predictive modeling", "statistical modeling",
        "generative ai", "llm", "large language model", "prompt engineering",
        "data engineering", "mlops", "python ai", "data mining"
    ],
    "uiux": [
        "ui", "ux", "user experience", "user interface", "figma", "adobe xd",
        "wireframe", "design system", "prototype", "usability testing", "user research",
        "information architecture", "interaction design", "visual design", "responsive design",
        "accessibility", "design thinking", "sketch", "invision", "user flows",
        "mockups", "design principles", "front-end design", "a/b testing", "human-computer interaction"
    ]
}

# Flatten keyword list for matching
all_domain_keywords = set(kw.lower() for keywords in target_domains.values() for kw in keywords)

# Scoring function
def domain_fit_score(row):
    combined_text = f"{row.get('title', '')} {row.get('descriptionText', '')} {' '.join(row.get('company.industries', []))} {' '.join(row.get('company.specialities', []))}".lower()
    matched = sum(1 for kw in all_domain_keywords if kw in combined_text)
    return round(min(matched / 5.0, 1.0), 2)

# Apply
df['kpi_domain_fit'] = df.apply(domain_fit_score, axis=1)

# Show output
# print(df[['title', 'kpi_domain_fit']].head())

"""## KPI 3: Seniority Alignment KPI

"""

# Inferred from descriptionText

seniority_high_keywords = ['mid-senior', 'senior', 'lead', 'director', 'executive']
seniority_low_keywords = ['internship', 'intern', 'entry level', 'junior']

def seniority_alignment_from_description(text):
    text = str(text).lower()

    if any(keyword in text for keyword in seniority_low_keywords):
        return 0.2
    elif any(keyword in text for keyword in seniority_high_keywords):
        return 1.0
    else:
        return 0.5

df['kpi_seniority_alignment'] = df['descriptionText'].apply(seniority_alignment_from_description)

# print results
# print(df[['title', 'kpi_seniority_alignment']].head())

"""## KPI 4: Location Priority KPI"""

preferred_countries = ['united states', 'usa', 'us', 'uk', 'Canada', 'United Kingdom', 'Germany', 'Netherlands', "Saudia Arab", "UAE"]

def location_priority_score(locations):
    if isinstance(locations, list):
        for loc in locations:
            country = str(loc.get('parsed', {}).get('country', '')).lower()
            if any(pref in country for pref in preferred_countries):
                return 1.0
        return 0.6
    return 0.5

df['kpi_location_priority'] = df['company.locations'].apply(location_priority_score)
# print(df[['title', 'company.locations', 'kpi_location_priority']].head())

"""## KPI 5: Remote Type KPI"""

def remote_type_score(row):
    workplace = str(row.get('workplaceType', '')).lower()
    if 'remote' in workplace:
        return 1.0
    elif 'hybrid' in workplace:
        return 0.7
    else:
        return 0.3

df['kpi_remote_type'] = df.apply(remote_type_score, axis=1)
# print(df[['title', 'workplaceType', 'kpi_remote_type']].head())

def remote_score(remote_flag, loc_type):
    if remote_flag is True:
        return 1.0
    elif isinstance(loc_type, str) and "HYBRID" in loc_type.upper():
        return 0.8
    else:
        return 0.5

df['kpi_remote'] = df.apply(
    lambda row: remote_score(row.get('Remote', False), row.get('Location Type', '')),
    axis=1
)
# print(df[['Job Title', 'Remote', 'Location Type', 'kpi_remote']])

"""## KPI 6: Salary Attractiveness KPI"""

def salary_score(row):
    salary = row.get('salary', {})
    min_salary = salary.get('min')
    max_salary = salary.get('max')

    try:
        if min_salary is not None and max_salary is not None:
            avg_salary = (float(min_salary) + float(max_salary)) / 2
        elif min_salary is not None:
            avg_salary = float(min_salary)
        elif max_salary is not None:
            avg_salary = float(max_salary)
        else:
            return 0.5  # Missing salary info
    except:
        return 0.5

    if avg_salary >= 100:  # High hourly/daily rate (e.g., contractor)
        return 1.0
    elif avg_salary >= 50:
        return 0.8
    elif avg_salary >= 30:
        return 0.6
    elif avg_salary >= 15:
        return 0.4
    else:
        return 0.2

df['kpi_salary'] = df.apply(salary_score, axis=1)
# print(df[['title', 'kpi_salary']].head())

"""## KPI 7: Company Size KPI"""

def company_size_score(emp_count):
    try:
        count = int(emp_count)
    except:
        return 0.4  # default score if invalid or missing

    if count == 1:
        return 0.1
    elif 2 <= count <= 10:
        return 0.2
    elif 11 <= count <= 50:
        return 0.3
    elif 51 <= count <= 200:
        return 0.5
    elif 201 <= count <= 500:
        return 0.6
    elif 501 <= count <= 1000:
        return 0.7
    elif 1001 <= count <= 5000:
        return 0.8
    elif 5001 <= count <= 10000:
        return 0.9
    else:
        return 1.0

df['kpi_company_size'] = df['company.employeeCount'].apply(company_size_score)
# print(df[['title', 'company.employeeCount', 'kpi_company_size']].head())

"""## KPI 8: Company Popularity KPI"""

def company_popularity_score(followers):
    try:
        followers = int(followers)
    except:
        return 0.4  # default if missing

    if followers > 500000:
        return 1.0
    elif followers > 100000:
        return 0.9
    elif followers > 50000:
        return 0.75
    elif followers > 10000:
        return 0.6
    elif followers > 1000:
        return 0.5
    else:
        return 0.3

df['kpi_company_popularity'] = df['company.followerCount'].apply(company_popularity_score)
# print(df[['title', 'company.followerCount', 'kpi_company_popularity']].head())

"""## KPI 9: Company Industry Match KPI"""

preferred_industries = [
    "Information Technology", "Computer Software", "AI", "Internet", "Software Development",
    "Staffing and Recruiting", "Web Development", "Machine Learning", "IT Services"
]

def industry_match_score(industry_list):
    if not isinstance(industry_list, list):
        return 0.4

    match_count = sum(1 for industry in industry_list if industry.lower() in [x.lower() for x in preferred_industries])
    return round(min(match_count / 3.0, 1.0), 2)

df['kpi_industry_match'] = df['company.industries'].apply(industry_match_score)
# print(df[['title', 'company.industries', 'kpi_industry_match']].head())

"""## KPI 10: Job Popularity KPI"""

def job_popularity_score(views):
    try:
        views = int(views)
    except:
        return 0.4

    if views >= 10000:
        return 1.0
    elif views >= 5000:
        return 0.8
    elif views >= 1000:
        return 0.6
    elif views >= 300:
        return 0.4
    else:
        return 0.2

df['kpi_job_popularity'] = df['views'].apply(job_popularity_score)
# print(df[['title', 'views', 'kpi_job_popularity']].head())

"""## KPI 11: Job Freshness KPI"""

from datetime import datetime

def job_freshness_score(posted_date):
    try:
        posted = datetime.fromisoformat(posted_date.replace("Z", ""))
        days_old = (datetime.now(timezone.utc) - posted).days
    except:
        return 0.5

    if days_old <= 1:
        return 1.0
    elif days_old <= 3:
        return 0.9
    elif days_old <= 7:
        return 0.8
    elif days_old <= 14:
        return 0.6
    elif days_old <= 30:
        return 0.4
    else:
        return 0.2

df['kpi_job_freshness'] = df['postedDate'].apply(job_freshness_score)
# print(df[['title', 'postedDate', 'kpi_job_freshness']].head())

"""## KPI 12: Employment Type KPI"""

preferred_types = ['full_time', 'contract']

def employment_type_score(emp_type):
    if isinstance(emp_type, str):
        emp_type = emp_type.lower()
        if emp_type in preferred_types:
            return 1.0
        else:
            return 0.5
    return 0.4

df['kpi_employment_type'] = df['employmentType'].apply(employment_type_score)
# print(df[['title', 'employmentType', 'kpi_employment_type']].head())

"""## KPI 13: Contact Info Present"""

def contact_info_score(text):
    if pd.isna(text):
        return 0
    text = str(text)
    email_pattern = r'[\w\.-]+@[\w\.-]+'
    phone_pattern = r'\+?\d[\d\-\s]{8,}'
    if re.search(email_pattern, text) or re.search(phone_pattern, text):
        return 1
    return 0

df['kpi_contact_info'] = df['descriptionText'].apply(contact_info_score)
# print(df[['title', 'kpi_contact_info']].head())

"""## KPI 14: Skills Explicitness KPI"""

skills_keywords = [
    "qa", "automation", "selenium", "cypress", "jmeter", "test case",
    "machine learning", "deep learning", "nlp", "ai", "ml", "pytorch", "tensorflow", "keras",
    "react", "vue", "angular", "javascript", "html", "css", "node", "express", "flask", "django",
    "figma", "adobe xd", "sketch", "wireframe", "prototype", "user research"
]

def skills_explicitness(text):
    if pd.isna(text):
        return 0.0
    text = text.lower()
    match_count = sum(1 for skill in skills_keywords if skill in text)
    return round(min(match_count / 5.0, 1.0), 2)

df['kpi_skills_explicitness'] = df['descriptionText'].apply(skills_explicitness)
# print(df[['title', 'kpi_skills_explicitness']].head())

"""## KPI 15: Experience Threshold KPI"""

experience_keywords = [
    '3+ years', '4+ years', '5+ years', '6+ years', '7+ years',
    '8+ years', 'experience with', 'mid-senior', 'senior'
]

# Patterns to identify seniority
seniority_high = ['mid-senior level', 'senior', 'director', 'executive']
seniority_low = ['internship', 'entry level', 'junior']

# Function to extract and score experience/seniority from descriptionText
def experience_score_from_description(desc):
    desc = desc.lower().strip() if pd.notna(desc) else ''

    # Look for seniority signals in description text
    if re.search(r'\bintern(ship)?\b', desc):
        return 0.0
    elif re.search(r'\b(entry level|junior)\b', desc):
        return 0.2
    elif any(kw in desc for kw in experience_keywords):
        return 1.0
    else:
        return 0.5

# Apply the function
df['kpi_experience_threshold'] = df['descriptionText'].apply(experience_score_from_description)

# print results
# print(df[['title', 'descriptionText', 'kpi_experience_threshold']].head(5))

"""## Final Step: Score Aggregation and Tier Assignment
We now calculate the weighted score and classify each job as:
- **Green** (â‰¥ 0.80)
- **Yellow** (0.60â€“0.79)
- **Red** (< 0.60)

"""

kpi_columns = [col for col in df.columns if col.startswith('kpi_')]

# Calculate the final score as mean of all KPIs
df['final_score'] = df[kpi_columns].mean(axis=1).round(2)

# Assign tiers based on final_score
def assign_tier(score):
    if score >= 0.80:
        return "Green"
    elif score >= 0.60:
        return "Yellow"
    else:
        return "Red"

df['tier'] = df['final_score'].apply(assign_tier)

# print final results
print(df[['title', 'final_score', 'tier'] + kpi_columns].head(31))


# Replace all NaN with None (which becomes null in JSON)
# df = df.where(pd.notnull(df), None)

# # Convert DataFrame to list of dicts
# output_data = df.to_dict(orient='records')

# # Save to JSON file
# with open('data/scored_jobs_output.json', 'w', encoding='utf-8') as f:
#     json.dump(output_data, f, ensure_ascii=False, indent=2)
df = df.where(pd.notnull(df), None)
df.to_json('data/scored_jobs_output.json', orient='records', force_ascii=False, indent=2)


print("Output saved to 'scored_jobs_output.json'")

