# -*- coding: utf-8 -*-
"""LinkedIn_AIML (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SvvCZm_1x4vt4jNtxWZ3bq6Sh6H2TuAy

## Importing Required Libraries and Loading the Data
"""


import json
import pandas as pd
import re
import string
from datetime import datetime, timezone
# from IPython.print import print

file_path = r'C:\Users\Dell\Desktop\linkedin project\linkedin-scrape-data\data\filtered.json'  # <-- "r" handles backslashes'  # Use relative path for Node.js compatibility

#Load JSON data
with open(file_path, 'r', encoding='utf-8') as f:
    data = json.load(f)

# Normalize JSON depending on structure
if isinstance(data, dict) and 'data' in data:
    jobs = data['data']
elif isinstance(data, list):
    jobs = data
else:
    raise ValueError("Unrecognized JSON structure.")

# Convert to DataFrame
df = pd.json_normalize(jobs)


# Preview
print(f" Remote jobs found: {df.shape[0]}")
# print(df[['id', 'title', 'company.name', 'location.linkedinText', 'workRemoteAllowed']].head())

"""## KPI 1: Job Description Quality KPI"""

def jd_quality_score(text):
    text = str(text)
    score = 0.0
    length = len(text)

    # Length check
    if length > 300:
        score += 0.4

    # Bullet point or list style formatting
    if '-' in text or 'â€¢' in text:
        score += 0.2

    # Structure keywords
    if any(kw in text.lower() for kw in ['responsibilities', 'requirements', 'qualifications', 'skills']):
        score += 0.2

    # Minimal punctuation noise
    symbol_count = sum(1 for char in text if char in string.punctuation)
    symbol_ratio = symbol_count / max(length, 1)
    if symbol_ratio < 0.05:
        score += 0.2

    return round(min(score, 1.0), 2)

df['kpi_jd_quality'] = df['descriptionText'].apply(jd_quality_score)
# print(df[['title', 'kpi_jd_quality']].head())

"""## KPI 2: Domain Fit KPI (QA, Test Automation, Web Dev, AI, ML, UI/UX)

"""

target_domains = {
    "qa": [
        "qa", "quality assurance", "test automation", "testing", "manual testing",
        "test case", "test plan", "selenium", "cypress", "jmeter", "test rail",
        "jira", "bug report", "defect tracking", "regression testing", "functional testing",
        "performance testing", "security testing", "api testing", "ui testing",
        "user acceptance testing", "uat", "agile testing", "scrum", "ci/cd testing"
    ],
    "web": [
        "frontend", "backend", "web developer", "javascript", "react", "vue",
        "angular", "html", "css", "node", "python", "django", "flask", "java",
        "spring boot", "c#", ".net", "php", "laravel", "ruby on rails", "go",
        "golang", "express.js", "typescript", "rest api", "graphql", "docker",
        "kubernetes", "aws", "azure", "gcp", "sql", "mongodb", "postgresql",
        "microservices", "redux", "webpack", "babel", "next.js", "nuxt.js"
    ],
    "ai": [
        "ai", "ml", "machine learning", "deep learning", "data scientist", "pytorch",
        "tensorflow", "keras", "scikit-learn", "nlp", "natural language processing",
        "computer vision", "reinforcement learning", "data analysis", "r", "julia",
        "spark", "hadoop", "neural networks", "predictive modeling", "statistical modeling",
        "generative ai", "llm", "large language model", "prompt engineering",
        "data engineering", "mlops", "python ai", "data mining"
    ],
    "uiux": [
        "ui", "ux", "user experience", "user interface", "figma", "adobe xd",
        "wireframe", "design system", "prototype", "usability testing", "user research",
        "information architecture", "interaction design", "visual design", "responsive design",
        "accessibility", "design thinking", "sketch", "invision", "user flows",
        "mockups", "design principles", "front-end design", "a/b testing", "human-computer interaction"
    ]
}

# Flatten keyword list for matching
all_domain_keywords = set(kw.lower() for keywords in target_domains.values() for kw in keywords)

# Scoring function
def domain_fit_score(row):
    combined_text = f"{row.get('title', '')} {row.get('descriptionText', '')} {' '.join(row.get('company.industries', []))} {' '.join(row.get('company.specialities', []))}".lower()
    matched = sum(1 for kw in all_domain_keywords if kw in combined_text)
    return round(min(matched / 5.0, 1.0), 2)

# Apply
df['kpi_domain_fit'] = df.apply(domain_fit_score, axis=1)

# Show output
# print(df[['title', 'kpi_domain_fit']].head())

"""## KPI 3: Seniority Alignment KPI

"""

# Inferred from descriptionText

seniority_high_keywords = ['mid-senior', 'senior', 'lead', 'director', 'executive']
seniority_low_keywords = ['internship', 'intern', 'entry level', 'junior']

def seniority_alignment_from_description(text):
    text = str(text).lower()

    if any(keyword in text for keyword in seniority_low_keywords):
        return 0.2
    elif any(keyword in text for keyword in seniority_high_keywords):
        return 1.0
    else:
        return 0.5

df['kpi_seniority_alignment'] = df['descriptionText'].apply(seniority_alignment_from_description)

# print results
# print(df[['title', 'kpi_seniority_alignment']].head())

"""## KPI 4: Location Priority KPI"""

preferred_countries = ['united states', 'usa', 'us', 'uk', 'Canada', 'United Kingdom', 'Germany', 'Netherlands', "Saudia Arab", "UAE"]

def location_priority_score(locations):
    if isinstance(locations, list):
        for loc in locations:
            country = str(loc.get('parsed', {}).get('country', '')).lower()
            if any(pref in country for pref in preferred_countries):
                return 1.0
        return 0.6
    return 0.5

df['kpi_location_priority'] = df['company.locations'].apply(location_priority_score)
# print(df[['title', 'company.locations', 'kpi_location_priority']].head())


'''## KPI 5: Company Specialties Match KPI'''

target_specialties = [
    # QA & Testing
    "qa", "quality assurance", "test automation", "testing", "manual testing",
    "selenium", "cypress", "playwright", "jmeter", "postman", "api testing",
    "performance testing", "security testing", "regression testing", "functional testing",
    "unit testing", "integration testing", "test case", "test plan", "jira", "testrail",
    "agile testing", "bdd", "tdd", "cucumber", "qa engineer", "software tester",

    # Web Development (Frontend & Backend)
    "frontend", "backend", "web development", "web developer", "full stack",
    "javascript", "typescript", "react", "angular", "vue.js", "html", "css",
    "scss", "less", "bootstrap", "tailwind css", "webpack", "babel", "npm", "yarn",
    "redux", "next.js", "nuxt.js", "svelte", "dom", "node.js", "express.js",
    "python", "django", "flask", "java", "spring boot", "c#", ".net", "php",
    "laravel", "ruby", "rails", "go", "golang", "rest api", "graphql",
    "microservices", "api development", "web engineer",

    # AI, Machine Learning & Data Science
    "ai", "machine learning", "ml", "deep learning", "data science", "nlp",
    "artificial intelligence", "computer vision", "reinforcement learning",
    "data analysis", "data engineering", "mlops", "generative ai", "llm",
    "large language model", "prompt engineering", "statistical modeling",
    "predictive analytics", "r", "pytorch", "tensorflow", "keras", "scikit-learn",
    "pandas", "numpy", "scipy", "data visualization", "tableau", "power bi",
    "big data", "hadoop", "spark", "data scientist", "ml engineer", "ai engineer",

    # UI/UX Design
    "ui", "ux", "ui/ux", "user interface", "user experience", "design", "figma",
    "user research", "usability testing", "wireframing", "prototyping", "design systems",
    "information architecture", "interaction design", "visual design", "responsive design",
    "accessibility", "adobe xd", "sketch", "invision", "user flows", "mockups",
    "design thinking", "human-computer interaction", "product design", "service design",

    # Software Engineering, DevOps, Cloud & Infrastructure
    "software engineering", "devops", "cloud", "infrastructure",
    "software development", "agile", "scrum", "kanban", "git", "version control",
    "ci/cd", "continuous integration", "continuous delivery", "containerization",
    "docker", "kubernetes", "aws", "azure", "gcp", "cloud computing",
    "system design", "architecture", "linux", "unix", "scripting", "bash", "shell",
    "automation", "security", "cybersecurity", "networking", "virtualization",
    "ansible", "terraform", "jenkins", "gitlab ci", "github actions", "sre",
    "site reliability engineering", "database", "sql", "nosql", "mongodb",
    "postgresql", "mysql", "redis", "database management", "system administration",
    "backend engineer", "network engineer", "solutions architect"
]

def company_specialties_score(specialties):
    if not isinstance(specialties, list):
        return 0.0
    
    matches = [spec for spec in specialties if spec.lower().strip() in target_specialties]
    count = len(matches)

    if count >= 3:
        return 1.0
    elif count == 2:
        return 0.66
    elif count == 1:
        return 0.33
    else:
        return 0.0

df['kpi_company_specialties'] = df['company.specialities'].apply(company_specialties_score)

# Preview the result
# print(df[['title', 'company.specialities', 'kpi_company_specialties']].head())


"""## KPI 6: Salary Attractiveness KPI"""

def salary_score(row):
    salary_str = row.get('salary', '')
    if not isinstance(salary_str, str) or salary_str.strip() == '':
        return 0.5  # Missing or invalid salary string

    # Remove commas and extract numbers
    salary_str = salary_str.replace(',', '')
    matches = re.findall(r'\d+', salary_str)

    if not matches:
        return 0.5

    # Convert to float and calculate average
    try:
        salary_values = list(map(float, matches))
        if len(salary_values) == 1:
            avg_salary = salary_values[0]
        else:
            avg_salary = sum(salary_values) / len(salary_values)
    except:
        return 0.5

    # Salary scoring thresholds
    if avg_salary >= 200000:
        return 1.0
    elif avg_salary >= 150000:
        return 0.8
    elif avg_salary >= 100000:
        return 0.6
    elif avg_salary >= 60000:
        return 0.4
    else:
        return 0.2

df['kpi_salary'] = df.apply(salary_score, axis=1)
# print(df[['title', 'salary', 'kpi_salary']].head())


"""## KPI 7: Company Size KPI"""

def company_size_score(emp_count):
    try:
        count = int(emp_count)
    except:
        return 0.4  # default score if invalid or missing

    if count == 1:
        return 0.1
    elif 2 <= count <= 10:
        return 0.2
    elif 11 <= count <= 50:
        return 0.3
    elif 51 <= count <= 200:
        return 0.5
    elif 201 <= count <= 500:
        return 0.6
    elif 501 <= count <= 1000:
        return 0.7
    elif 1001 <= count <= 5000:
        return 0.8
    elif 5001 <= count <= 10000:
        return 0.9
    else:
        return 1.0

df['kpi_company_size'] = df['company.employeeCount'].apply(company_size_score)
# print(df[['title', 'company.employeeCount', 'kpi_company_size']].head())

"""## KPI 8: Company Popularity KPI"""

def company_popularity_score(followers):
    try:
        followers = int(followers)
    except:
        return 0.4  # default if missing

    if followers > 500000:
        return 1.0
    elif followers > 100000:
        return 0.9
    elif followers > 50000:
        return 0.75
    elif followers > 10000:
        return 0.6
    elif followers > 1000:
        return 0.5
    else:
        return 0.3

df['kpi_company_popularity'] = df['company.followerCount'].apply(company_popularity_score)
# print(df[['title', 'company.followerCount', 'kpi_company_popularity']].head())

"""## KPI 9: Company Industry Match KPI"""

preferred_industries = [
    "Information Technology", "Computer Software", "AI", "Internet", "Software Development",
    "Staffing and Recruiting", "Web Development", "Machine Learning", "IT Services",
    "Fintech", "Edtech", "Healthtech", "Crypto", "Logistics", "Media",
    "E-commerce", "Ride hailing"
]

def industry_match_score(industry_list):
    if not isinstance(industry_list, list):
        return 0.4  # fallback score

    matches = sum(1 for industry in industry_list if any(pref.lower() in industry.lower() for pref in preferred_industries))
    return round(min(matches / 3.0, 1.0), 2)

df['kpi_industry_match'] = df['company.industries'].apply(industry_match_score)
# print(df[['title', 'company.industries', 'kpi_industry_match']].head())


"""## KPI 10: Job Popularity KPI"""

def job_popularity_score(views):
    try:
        views = int(views)
    except:
        return 0.4

    if views >= 10000:
        return 1.0
    elif views >= 5000:
        return 0.8
    elif views >= 1000:
        return 0.6
    elif views >= 300:
        return 0.4
    else:
        return 0.2

df['kpi_job_popularity'] = df['views'].apply(job_popularity_score)
# print(df[['title', 'views', 'kpi_job_popularity']].head())

"""## KPI 11: Job Freshness KPI"""

from datetime import datetime

def job_freshness_score(posted_date):
    try:
        posted = datetime.fromisoformat(posted_date.replace("Z", ""))
        days_old = (datetime.now(timezone.utc) - posted).days
    except:
        return 0.5

    if days_old <= 1:
        return 1.0
    elif days_old <= 3:
        return 0.9
    elif days_old <= 7:
        return 0.8
    elif days_old <= 14:
        return 0.6
    elif days_old <= 30:
        return 0.4
    else:
        return 0.2

df['kpi_job_freshness'] = df['postedDate'].apply(job_freshness_score)
# print(df[['title', 'postedDate', 'kpi_job_freshness']].head())

"""## KPI 12: Employment Type KPI"""

preferred_types = ['full_time', 'contract']

def employment_type_score(emp_type):
    if isinstance(emp_type, str):
        emp_type = emp_type.lower()
        if emp_type in preferred_types:
            return 1.0
        else:
            return 0.5
    return 0.4

df['kpi_employment_type'] = df['employmentType'].apply(employment_type_score)
# print(df[['title', 'employmentType', 'kpi_employment_type']].head())

"""## KPI 13: Contact Info Present"""

def contact_info_score(text):
    if pd.isna(text):
        return 0.0

    text = str(text)
    score = 0.0

    email_pattern = r'[\w\.-]+@[\w\.-]+'
    phone_pattern = r'\+?\d[\d\-\s]{8,}'
    url_pattern = r'https?://[^\s)]+'

    if re.search(email_pattern, text):
        score += 0.33
    if re.search(phone_pattern, text):
        score += 0.33
    if re.search(url_pattern, text):
        score += 0.33

    return round(min(score, 1.0), 2)

df['kpi_contact_info'] = df['descriptionText'].apply(contact_info_score)
# print(df[['title', 'kpi_contact_info']].head())

"""## KPI 14: Skills Explicitness KPI"""

skills_keywords = [
    # QA & Testing Skills
    "qa", "quality assurance", "automation", "test automation", "selenium", "cypress",
    "playwright", "jmeter", "postman", "test case", "test plan", "bug tracking", "jira",
    "api testing", "performance testing", "security testing", "regression testing",
    "functional testing", "unit testing", "integration testing", "bdd", "tdd", "cucumber",
    "pytest", "junit", "testng", "software testing",

    # AI/Machine Learning/Data Science Skills
    "machine learning", "deep learning", "nlp", "ai", "ml", "pytorch", "tensorflow", "keras",
    "scikit-learn", "pandas", "numpy", "data analysis", "data modeling", "statistical analysis",
    "computer vision", "reinforcement learning", "generative ai", "llms", "prompt engineering",
    "data visualization", "matplotlib", "seaborn", "plotly", "spark", "hadoop", "etl", "data cleansing",

    # Web Development (Frontend & Backend) Skills
    "react", "vue", "angular", "javascript", "typescript", "html", "css", "scss", "less",
    "node", "express", "flask", "django", "spring boot", "c#", ".net", "php", "laravel",
    "ruby on rails", "go", "gin", "fastapi", "restful apis", "graphql", "microservices",
    "webpack", "babel", "redux", "next.js", "nuxt.js", "svelte", "bootstrap", "tailwind css",
    "web components", "responsive design", "server-side rendering",

    # UI/UX/Design Skills
    "figma", "adobe xd", "sketch", "wireframe", "prototype", "user research", "usability testing",
    "design systems", "information architecture", "interaction design", "visual design",
    "user flows", "mockups", "design thinking", "personas", "storyboarding", "user-centered design",

    # General Software Development, DevOps, Cloud & Database Skills
    "git", "version control", "docker", "kubernetes", "aws", "azure", "gcp", "cloud computing",
    "ci/cd", "continuous integration", "continuous delivery", "jenkins", "gitlab ci", "github actions",
    "linux", "shell scripting", "bash", "python scripting", "api design", "system design",
    "data structures", "algorithms", "problem-solving", "agile methodologies", "scrum", "kanban",
    "sql", "postgresql", "mysql", "mongodb", "redis", "database design", "database management",
    "debugging", "troubleshooting", "software architecture", "clean code", "code review"
]

def skills_explicitness(text):
    if pd.isna(text):
        return 0.0
    text = text.lower()
    match_count = sum(1 for skill in skills_keywords if skill in text)
    return round(min(match_count / 5.0, 1.0), 2)

df['kpi_skills_explicitness'] = df['descriptionText'].apply(skills_explicitness)
# print(df[['title', 'kpi_skills_explicitness']].head())

"""## KPI 15: Experience Threshold KPI"""

experience_keywords = [
    '3+ years', '4+ years', '5+ years', '6+ years', '7+ years',
    '8+ years', 'experience with', 'mid-senior', 'senior'
]

# Patterns to identify seniority
seniority_high = ['mid-senior level', 'senior', 'director', 'executive']
seniority_low = ['internship', 'entry level', 'junior']

# Function to extract and score experience/seniority from descriptionText
def experience_score_from_description(desc):
    desc = desc.lower().strip() if pd.notna(desc) else ''

    # Look for seniority signals in description text
    if re.search(r'\bintern(ship)?\b', desc):
        return 0.0
    elif re.search(r'\b(entry level|junior)\b', desc):
        return 0.2
    elif any(kw in desc for kw in experience_keywords):
        return 1.0
    else:
        return 0.5

# Apply the function
df['kpi_experience_threshold'] = df['descriptionText'].apply(experience_score_from_description)

# print results
# print(df[['title', 'descriptionText', 'kpi_experience_threshold']].head(5))

"""## Final Step: Score Aggregation and Tier Assignment
We now calculate the weighted score and classify each job as:
- **Green** (â‰¥ 0.80)
- **Yellow** (0.60â€“0.79)
- **Red** (< 0.60)

"""

kpi_columns = [col for col in df.columns if col.startswith('kpi_')]

# Calculate the final score as mean of all KPIs
df['final_score'] = df[kpi_columns].mean(axis=1).round(2)

# Assign tiers based on final_score
def assign_tier(score):
    if score >= 0.70:
        return "Green"
    elif score >= 0.50:
        return "Yellow"
    else:
        return "Red"

df['tier'] = df['final_score'].apply(assign_tier)

# print final results
print(df[['title', 'final_score', 'tier'] + kpi_columns].head(100))


# Replace all NaN with None (which becomes null in JSON)
# df = df.where(pd.notnull(df), None)

# # Convert DataFrame to list of dicts
# output_data = df.to_dict(orient='records')

# # Save to JSON file
# with open('data/scored_jobs_output.json', 'w', encoding='utf-8') as f:
#     json.dump(output_data, f, ensure_ascii=False, indent=2)
df = df.where(pd.notnull(df), None)
df.to_json('data/scored_jobs_output.json', orient='records', force_ascii=False, indent=2)


print("Output saved to 'scored_jobs_output.json'")

